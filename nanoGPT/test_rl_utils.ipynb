{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "from model import GPTConfig, GPT\n",
    "from tokenizers import Tokenizer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import chess.pgn\n",
    "import io\n",
    "from contextlib import nullcontext\n",
    "from rl_utils import get_rewards, pad_arrays, get_reverse_discount_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"7\"\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 102.85M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(23296, 768)\n",
       "    (wpe): Embedding(768, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=23296, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ckpt_path = os.path.join(\"out_chess_llm_q_iteration\", 'ckpt900.pt')\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "checkpoint_model_args = checkpoint['model_args']\n",
    "# force these config attributes to be equal otherwise we can't even resume training\n",
    "# the rest of the attributes (e.g. dropout) can stay as desired from command line\n",
    "# create the model\n",
    "gptconf = GPTConfig(**checkpoint_model_args)\n",
    "model = GPT(gptconf)\n",
    "state_dict = checkpoint['model']\n",
    "# fix the keys of the state dictionary :(\n",
    "# honestly no idea how checkpoints sometimes get this prefix, have to debug more\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict)\n",
    "iter_num = checkpoint['iter_num']\n",
    "best_val_loss = checkpoint['best_val_loss']\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"/data/evan/CS285_Final_Project/model/tokenizer.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_type = 'cpu'\n",
    "ptdtype = torch.bfloat16\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = torch.IntTensor([0]).to(device)\n",
    "board = chess.Board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1, 23296])\n",
      "torch.Size([1, 23296])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 22044 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/data/evan/CS285_Final_Project/nanoGPT/test_rl_utils.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Bjiaolab-cluster/data/evan/CS285_Final_Project/nanoGPT/test_rl_utils.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m ctx:\n\u001b[0;32m----> <a href='vscode-notebook-cell://tunnel%2Bjiaolab-cluster/data/evan/CS285_Final_Project/nanoGPT/test_rl_utils.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     idx_next, logit, prob \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mget_next_move(idx_list, board, tokenizer)\n",
      "File \u001b[0;32m~/CS285_Final_Project/nanoGPT/model.py:255\u001b[0m, in \u001b[0;36mGPT.get_next_move\u001b[0;34m(self, idx, board, tokenizer)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mprint\u001b[39m(legality_mask\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    254\u001b[0m prob \u001b[39m=\u001b[39m action_distribution\u001b[39m.\u001b[39mlog_prob(idx_next)\n\u001b[0;32m--> 255\u001b[0m logit \u001b[39m=\u001b[39m logits[idx_next\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m)]\n\u001b[1;32m    258\u001b[0m \u001b[39mreturn\u001b[39;00m idx_next, logit, prob\n",
      "\u001b[0;31mIndexError\u001b[0m: index 22044 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "with ctx:\n",
    "    idx_next, logit, prob = model.get_next_move(idx_list, board, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data/evan/CS285_Final_Project/nanoGPT/test_rl_utils.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://tunnel%2Bjiaolab-cluster/data/evan/CS285_Final_Project/nanoGPT/test_rl_utils.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m idx_next\u001b[39m.\u001b[39;49mitem()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "idx_next.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "batch_size = 2\n",
    "\n",
    "gradient_accumulation_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ctx:\n",
    "    probs, boards, dones = model.sample_legal_trajectories(batch_size, tokenizer, device=device)\n",
    "\n",
    "    # calculate rewards for that trajectory\n",
    "    targets, masks = get_rewards(boards, dones)\n",
    "\n",
    "    full_masks = torch.Tensor(pad_arrays(masks)).to(device)\n",
    "\n",
    "    full_targets = torch.Tensor(pad_arrays(targets)).to(device)\n",
    "\n",
    "    inputs = full_masks * probs\n",
    "\n",
    "    loss = loss_fn(inputs, full_targets) / full_masks.sum()\n",
    "\n",
    "    loss = loss / gradient_accumulation_steps\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ctx:\n",
    "    probs, boards, dones = model.sample_legal_trajectories(2, tokenizer, device=device)\n",
    "\n",
    "    # calculate rewards for that trajectory\\\n",
    "    targets_d, masks_d = get_reverse_discount_rewards(boards, 0.95)\n",
    "\n",
    "    targets, masks = get_rewards(boards, dones)\n",
    "\n",
    "    full_masks = torch.Tensor(pad_arrays(masks)).to(device)\n",
    "\n",
    "    full_target = torch.Tensor(pad_arrays(targets)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (torch.nn.functional.binary_cross_entropy_with_logits(probs * full_masks, full_target, reduction='sum') / full_masks.sum()) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_masks.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1/2-1/2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boards[1].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Board.result of Board('7k/Q5R1/6Qp/7P/8/6P1/5PK1/8 b - - 0 54')>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boards[1].result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.05799111, 1.        , 0.06104327, 1.        , 0.06425608,\n",
       "        1.        , 0.06763798, 1.        , 0.07119787, 1.        ,\n",
       "        0.07494513, 1.        , 0.07888961, 1.        , 0.08304169,\n",
       "        1.        , 0.08741231, 1.        , 0.09201296, 1.        ,\n",
       "        0.09685574, 1.        , 0.10195341, 1.        , 0.10731938,\n",
       "        1.        , 0.11296777, 1.        , 0.11891344, 1.        ,\n",
       "        0.12517204, 1.        , 0.13176005, 1.        , 0.13869479,\n",
       "        1.        , 0.14599451, 1.        , 0.15367843, 1.        ,\n",
       "        0.16176677, 1.        , 0.17028081, 1.        , 0.17924296,\n",
       "        1.        , 0.1886768 , 1.        , 0.19860716, 1.        ,\n",
       "        0.20906017, 1.        , 0.22006333, 1.        , 0.23164562,\n",
       "        1.        , 0.24383749, 1.        , 0.25667104, 1.        ,\n",
       "        0.27018004, 1.        , 0.28440005, 1.        , 0.29936847,\n",
       "        1.        , 0.3151247 , 1.        , 0.33171022, 1.        ,\n",
       "        0.34916865, 1.        , 0.36754595, 0.99999999, 0.38689047,\n",
       "        0.99999984, 0.40725312, 0.99999688, 0.4286875 , 0.9999375 ,\n",
       "        0.45125   , 0.99875   , 0.475     , 0.975     , 0.5       ,\n",
       "        0.5       ]),\n",
       " array([1.        , 0.14599451, 1.        , 0.15367843, 1.        ,\n",
       "        0.16176677, 1.        , 0.17028081, 1.        , 0.17924296,\n",
       "        1.        , 0.1886768 , 1.        , 0.19860716, 1.        ,\n",
       "        0.20906017, 1.        , 0.22006333, 1.        , 0.23164562,\n",
       "        1.        , 0.24383749, 1.        , 0.25667104, 1.        ,\n",
       "        0.27018004, 1.        , 0.28440005, 1.        , 0.29936847,\n",
       "        1.        , 0.3151247 , 1.        , 0.33171022, 1.        ,\n",
       "        0.34916865, 1.        , 0.36754595, 0.99999999, 0.38689047,\n",
       "        0.99999984, 0.40725312, 0.99999688, 0.4286875 , 0.9999375 ,\n",
       "        0.45125   , 0.99875   , 0.475     , 0.975     , 0.5       ,\n",
       "        0.5       ])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1007e+00, -8.5758e-01, -6.8355e-01, -4.4358e+00, -5.2183e-01,\n",
       "         -3.3869e-02, -1.7516e+00, -5.8120e-01, -6.8881e+00, -9.0856e-01,\n",
       "         -8.3140e-01, -9.6628e-01, -1.3158e+00, -4.5910e-01, -1.2073e-01,\n",
       "         -7.5612e-01, -5.0810e+00, -1.8676e+00, -2.4674e+00, -1.2607e+00,\n",
       "         -2.3355e-02, -2.1168e+00, -1.3593e+00, -2.5023e-01, -2.0986e+00,\n",
       "         -1.8771e+00, -3.7050e-01, -1.6851e+00, -4.9095e-03, -4.4382e-01,\n",
       "         -1.6760e+00, -2.0921e+00, -2.0608e+00, -7.0795e-01, -2.5383e+00,\n",
       "         -3.6730e-01, -1.5822e+00, -3.3371e+00, -4.6375e-01, -8.0519e-01,\n",
       "         -9.4756e-01, -1.2960e-02, -9.5324e-01, -7.2157e-01, -3.0367e-01,\n",
       "         -1.6993e+00, -2.9645e+00, -3.4643e+00, -3.3809e+00, -3.6018e-01,\n",
       "         -8.3803e-02, -2.0811e+00, -2.9186e+00, -1.0013e+00, -1.0997e+00,\n",
       "         -3.2565e+00, -2.7185e-01, -8.6739e-01, -5.1926e-01, -3.3354e-01,\n",
       "         -3.5707e+00, -2.4740e+00, -5.4396e-01, -1.8899e+00, -4.9152e-02,\n",
       "         -3.4279e+00, -1.3927e-01, -1.2602e-01, -3.6075e+00, -1.0307e-01,\n",
       "         -9.6917e-01, -7.9720e-01, -9.8262e-01, -1.8445e+00, -5.8513e-01,\n",
       "         -5.4936e-01, -1.3277e-01, -4.5766e+00, -1.1420e+00, -1.3187e+00,\n",
       "         -8.0876e-01, -1.0987e+00, -2.4270e+00, -3.5182e+00, -2.8992e-01,\n",
       "         -3.1999e+00, -4.5386e-01, -1.0116e+00, -1.7867e-01, -2.3666e+00,\n",
       "         -2.4844e+00, -3.0992e+00, -2.7473e-02, -3.8161e+00, -1.5694e+00,\n",
       "         -1.9590e+00, -3.3302e-02, -5.0602e-01, -9.8892e-01, -3.9532e-01,\n",
       "         -4.9522e-02, -6.0356e-01, -3.3590e-01, -1.2473e+00, -3.1795e-01,\n",
       "         -4.5359e+00, -8.4069e-01, -8.7635e-01, -1.0050e+00, -1.6553e+00,\n",
       "         -4.4835e+00, -1.0467e+00, -4.1071e-02, -7.2863e-01, -2.5106e+00,\n",
       "         -1.6503e+00, -1.9893e+00, -2.4642e+00, -9.2862e-01, -5.2094e-01,\n",
       "         -1.1770e+00, -3.6369e-01, -3.3019e-01, -6.5340e-01, -2.4989e+00,\n",
       "         -1.5301e+00, -3.1860e+00, -2.5729e+00, -1.7372e+00, -1.4731e+00,\n",
       "         -3.7083e+00, -2.4291e+00, -2.3438e+00, -3.2648e+00, -2.9819e+00,\n",
       "         -2.8797e+00, -2.2334e+00, -2.1001e+00, -1.8175e+00, -1.6167e+00,\n",
       "         -3.0183e-01, -1.3782e+00, -6.0135e-01, -3.1902e+00, -5.1565e-01,\n",
       "         -2.9142e+00, -6.3252e-01, -2.3696e+00, -1.3621e+00, -2.2950e+00,\n",
       "         -1.4352e+00, -3.4957e+00, -1.4638e+00, -3.6356e+00, -4.3082e+00,\n",
       "         -9.7498e-01, -1.8045e+00, -1.0473e+00, -4.0953e-01, -6.6118e-01,\n",
       "         -3.5802e+00, -3.4350e-01, -3.2708e+00, -1.4989e+00, -2.2363e+00,\n",
       "         -2.5288e+00, -4.6599e+00, -1.4542e+00, -3.2602e+00, -2.4161e+00,\n",
       "         -2.1822e+00, -1.8289e+00, -2.2161e+00, -3.4897e+00, -1.8878e+00,\n",
       "         -3.6421e+00, -1.3196e+00, -3.4939e+00, -5.9264e-01, -2.5905e+00,\n",
       "         -6.2271e-01, -3.1171e+00, -1.4426e+00, -6.8770e-01, -1.9184e+00,\n",
       "         -5.7442e+00, -9.0642e-01, -5.3678e-01, -1.9783e+00, -1.1027e+00,\n",
       "         -1.4707e-01, -1.2749e+00, -5.0536e-01, -7.9147e-01, -4.3192e-02],\n",
       "        [-9.1316e-01, -1.0673e+00, -4.5171e-01, -7.4167e-01, -5.2853e-01,\n",
       "         -3.6736e-02, -1.3474e-01, -6.6263e-02, -7.1335e-02, -4.9759e-01,\n",
       "         -1.4451e+00, -3.3097e-01, -2.5901e+00, -9.4124e-01, -3.6014e-01,\n",
       "         -2.5732e+00, -1.3964e+00, -1.6704e+00, -2.0795e+00, -4.1614e+00,\n",
       "         -1.7284e+00, -6.6567e-01, -3.9393e+00, -1.7935e-02, -6.7228e-02,\n",
       "         -6.3018e-01, -1.3048e+00, -8.3086e-02, -3.1358e-01, -2.0563e+00,\n",
       "         -6.2649e-01, -7.3783e-01, -5.7052e-01, -6.1398e-03, -5.7850e-01,\n",
       "         -4.6969e-01, -1.2984e+00, -2.4559e+00, -3.6934e+00, -1.0725e+00,\n",
       "         -1.0230e+00, -3.0264e-02, -4.4836e-02, -2.3149e-01, -1.6212e-01,\n",
       "         -4.2999e-02, -4.0549e+00, -8.1356e-01, -2.1143e-01, -2.7471e-01,\n",
       "         -2.2904e+00, -1.1922e+00, -5.0774e-01, -2.7248e-01, -2.1690e+00,\n",
       "         -3.9602e+00, -2.2425e+00, -3.9043e-01, -2.1962e-01, -2.0082e+00,\n",
       "         -5.0097e-01, -6.0798e-01, -7.5932e-01, -1.3946e+00, -5.7509e-01,\n",
       "         -1.3024e+00, -5.2301e-01, -8.9954e-02, -1.4154e+00, -1.9014e+00,\n",
       "         -4.4349e+00, -2.3379e+00, -2.8451e-01, -4.9696e-01, -1.7233e+00,\n",
       "         -1.3636e+00, -2.8115e-01, -8.5186e-01, -1.8420e-01, -3.1418e+00,\n",
       "         -5.9901e-01, -5.2932e-01, -3.2095e+00, -3.8477e+00, -1.9289e+00,\n",
       "         -3.5782e+00, -2.4431e+00, -1.2221e+00, -5.1443e-01, -5.4074e-01,\n",
       "         -2.5822e+00, -3.3844e+00, -1.7846e+00, -9.2468e-01, -2.5801e-01,\n",
       "         -1.8882e+00, -3.3614e+00, -3.9910e-01, -3.2612e+00, -8.9384e-01,\n",
       "         -2.0199e+00, -3.5372e+00, -3.7496e+00, -4.2014e+00, -2.1675e+00,\n",
       "         -2.4503e+00, -2.7763e+00, -2.4840e+00, -2.3596e+00, -1.6952e-01,\n",
       "         -5.1338e-01, -7.2303e-01, -3.3452e+00, -1.3074e+00, -1.1645e+00,\n",
       "         -2.7037e-01, -1.1043e+01, -1.7831e+00, -7.1287e+00, -2.9353e+00,\n",
       "         -1.5275e+00, -1.6966e+00, -2.8503e+00, -7.9860e+00, -3.4178e+00,\n",
       "         -3.8778e+00, -3.1291e+00, -6.7192e-01, -2.1817e+00, -1.2172e+00,\n",
       "         -5.1364e-01, -2.0760e+00, -5.0412e+00, -1.5569e+00, -9.4574e+00,\n",
       "         -1.8756e+00, -3.6538e+00, -7.2785e-01, -1.0339e+00, -5.7327e-01,\n",
       "         -4.6132e+00, -1.7022e+00, -3.4768e+00, -1.2547e+00, -4.6799e+00,\n",
       "         -1.0642e+00, -1.1292e+00, -3.8398e+00, -6.8067e+00, -1.1883e+00,\n",
       "         -3.8441e+00, -5.6517e+00, -1.2919e+00, -3.5555e+00, -3.9470e+00,\n",
       "         -1.9659e+00, -2.5048e+00, -1.6962e+00, -3.4138e+00, -3.7951e+00,\n",
       "         -1.9180e+00, -1.4374e+00, -5.5651e+00, -1.0392e+00, -1.0714e+01,\n",
       "         -1.6385e+00, -3.3966e+00, -1.0133e+00, -5.3545e+00, -2.5303e+00,\n",
       "         -2.7868e+00, -7.9007e-01, -5.6180e+00, -1.8733e+00, -7.3743e+00,\n",
       "         -4.1589e+00, -2.8986e+00, -1.3581e+00, -5.1917e+00, -1.0176e+00,\n",
       "         -2.2320e+00, -2.7684e+00, -2.2601e+00, -3.5009e-01, -3.3876e+00,\n",
       "         -3.0039e+00, -3.8915e+00, -1.5334e+00, -3.4749e+00, -3.6548e+00,\n",
       "         -3.0368e+00, -1.5502e+00, -1.5006e+00, -2.7815e+00, -5.4990e+00]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 96])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 96)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 96)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Board('r2q1r1k/1pp1p1bp/1n4p1/p3pb2/P3N1n1/3B1NB1/1PP2PPP/R2Q1RK1 w - - 4 15'),\n",
       " Board('B1b1rk2/p4pp1/5np1/1p3q2/P7/4B1P1/1P2nPKP/R2R4 w - - 1 22'),\n",
       " Board('2r3k1/p1r1bpp1/1pP1p2p/4P3/q1pB2P1/4P1QP/P5B1/2RR2K1 w - - 7 29'),\n",
       " Board('5r2/1p2r2B/n1p2kR1/3pN3/3P1P1R/4K3/1P5P/8 b - - 4 48')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for board in boards:\n",
    "    game = chess.pgn.Game()\n",
    "    node = game\n",
    "    for move in board.move_stack:\n",
    "        node = node.add_main_variation(move)\n",
    "    print(game, file=open(\"./eval_games.pgn\", 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
