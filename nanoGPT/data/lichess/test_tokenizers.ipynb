{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "import tiktoken\n",
    "from datasets import load_dataset # huggingface datasets\n",
    "from tokenizers.processors import TemplateProcessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_proc = 8\n",
    "\n",
    "# number of workers in load_dataset() call\n",
    "# best number might be different from num_proc above as it also depends on NW speed.\n",
    "# it is better than 1 usually though\n",
    "num_proc_load_dataset = num_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 40/40 [00:01<00:00, 26.84it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"evanfrick/lichess\", num_proc=num_proc_load_dataset)\n",
    "\n",
    "# owt by default only contains the 'train' split, so create a test split\n",
    "split_dataset = dataset[\"train\"].train_test_split(test_size=0.00025, seed=2357, shuffle=True)\n",
    "split_dataset['val'] = split_dataset.pop('test') # rename the test split to val\n",
    "\n",
    "# this results in:\n",
    "# >>> split_dataset\n",
    "# DatasetDict({\n",
    "#     train: Dataset({\n",
    "#         features: ['text'],\n",
    "#         num_rows: 8009762\n",
    "#     })\n",
    "#     val: Dataset({\n",
    "#         features: ['text'],\n",
    "#         num_rows: 4007\n",
    "#     })\n",
    "# })\n",
    "\n",
    "# we now want to tokenize the dataset. first define the encoding function (gpt2 bpe)\n",
    "tokenizer = Tokenizer.from_file(\"/data/evan/chess-llm/tokenizer.model\")\n",
    "tokenizer.build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'game', 'result'],\n",
       "        num_rows: 19052702\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['id', 'game', 'result'],\n",
       "        num_rows: 4765\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<w>e2-e4<b>e7-e6<w>d2-d3<b>d7-d5<w>Nb1-d2<b>Ng8-f6<w>Ng1-f3<b>c7-c5<w>g2-g3<b>Nb8-c6<w>Bf1-g2<b>Bf8-e7<w>O-O<b>O-O<w>Rf1-e1<b>b7-b5<w>e4-e5<b>Nf6-d7<w>Nd2-f1<b>a7-a5<w>h2-h4<b>c5-c4<w>d3-d4<b>b5-b4<w>c2-c3<b>a5-a4<w>a2-a3<b>b4xc3<w>b2xc3<b>Nc6-a5<w>h4-h5<b>Na5-b3<w>Ra1-a2<b>Nd7-b8<w>Bc1-f4<b>Nb8-a6<w>h5-h6<b>g7-g6<w>Nf1-h2<b>Na6-c7<w>Nh2-g4<b>Nc7-b5<w>Qd1-c2<b>Nb5xa3<w>Ra2xa3<b>Be7xa3<w>Ng4-f6+<b>Kg8-h8<w>Nf3-g5<b>Ba3-e7<w>Nf6xh7<b>a4-a3<w>Nh7xf8<b>Qd8xf8<w>Qc2-a2<b>Bc8-d7<w>Bg2-f3<b>Ra8-b8<w>Bf3-d1<b>Bd7-a4<w>Kg1-g2<b>Ba4-c6<w>Ng5-f3<b>Nb3-a5<w>Re1-h1<b>Rb8-b2<w>Qa2-a1<b>Na5-b3<w>Bd1xb3<b>c4xb3<w>Bf4-g5<b>Rb2-a2<w>Qa1-b1<b>Ra2-b2<w>Qb1-c1<b>Rb2-c2<w>Qc1-f4<b>b3-b2<w>Bg5-f6+'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset['train'][0]['game']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc.encode_ordinary(split_dataset['train'][0]['game']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 22908,\n",
       " 1,\n",
       " 22560,\n",
       " 0,\n",
       " 22974,\n",
       " 1,\n",
       " 22725,\n",
       " 0,\n",
       " 10215,\n",
       " 1,\n",
       " 14211,\n",
       " 0,\n",
       " 18693,\n",
       " 1,\n",
       " 23034,\n",
       " 0,\n",
       " 23235,\n",
       " 1,\n",
       " 21117,\n",
       " 0,\n",
       " 14625,\n",
       " 1,\n",
       " 14475,\n",
       " 0,\n",
       " 23247,\n",
       " 1,\n",
       " 23247,\n",
       " 0,\n",
       " 14403,\n",
       " 1,\n",
       " 22239,\n",
       " 0,\n",
       " 22911,\n",
       " 1,\n",
       " 9795,\n",
       " 0,\n",
       " 12549,\n",
       " 1,\n",
       " 23025,\n",
       " 0,\n",
       " 22134,\n",
       " 1,\n",
       " 22038,\n",
       " 0,\n",
       " 22140,\n",
       " 1,\n",
       " 22185,\n",
       " 0,\n",
       " 22587,\n",
       " 1,\n",
       " 22254,\n",
       " 0,\n",
       " 23031,\n",
       " 1,\n",
       " 22758,\n",
       " 0,\n",
       " 22707,\n",
       " 1,\n",
       " 17571,\n",
       " 0,\n",
       " 22896,\n",
       " 1,\n",
       " 8241,\n",
       " 0,\n",
       " 13743,\n",
       " 1,\n",
       " 20433,\n",
       " 0,\n",
       " 21189,\n",
       " 1,\n",
       " 9945,\n",
       " 0,\n",
       " 22833,\n",
       " 1,\n",
       " 22266,\n",
       " 0,\n",
       " 9597,\n",
       " 1,\n",
       " 5421,\n",
       " 0,\n",
       " 11523,\n",
       " 1,\n",
       " 19743,\n",
       " 0,\n",
       " 8871,\n",
       " 1,\n",
       " 546,\n",
       " 0,\n",
       " 19194,\n",
       " 1,\n",
       " 10830,\n",
       " 0,\n",
       " 18568,\n",
       " 1,\n",
       " 14991,\n",
       " 0,\n",
       " 18651,\n",
       " 1,\n",
       " 10845,\n",
       " 0,\n",
       " 19710,\n",
       " 1,\n",
       " 22809,\n",
       " 0,\n",
       " 5124,\n",
       " 1,\n",
       " 19974,\n",
       " 0,\n",
       " 18807,\n",
       " 1,\n",
       " 5799,\n",
       " 0,\n",
       " 7095,\n",
       " 1,\n",
       " 2421,\n",
       " 0,\n",
       " 18081,\n",
       " 1,\n",
       " 1461,\n",
       " 0,\n",
       " 5715,\n",
       " 1,\n",
       " 14721,\n",
       " 0,\n",
       " 16851,\n",
       " 1,\n",
       " 12495,\n",
       " 0,\n",
       " 11931,\n",
       " 1,\n",
       " 1089,\n",
       " 0,\n",
       " 5433,\n",
       " 1,\n",
       " 8241,\n",
       " 0,\n",
       " 16776,\n",
       " 1,\n",
       " 22932,\n",
       " 0,\n",
       " 12105,\n",
       " 1,\n",
       " 9027,\n",
       " 0,\n",
       " 21051,\n",
       " 1,\n",
       " 11379,\n",
       " 0,\n",
       " 12333,\n",
       " 1,\n",
       " 3003,\n",
       " 0,\n",
       " 5019,\n",
       " 1,\n",
       " 22986,\n",
       " 0,\n",
       " 8338]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode(split_dataset['train'][0]['game'], add_special_tokens=True).ids\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<w> e2-e4 <b> e7-e6 <w> d2-d3 <b> d7-d5 <w> Nb1-d2 <b> Ng8-f6 <w> Ng1-f3 <b> c7-c5 <w> g2-g3 <b> Nb8-c6 <w> Bf1-g2 <b> Bf8-e7 <w> O-O <b> O-O <w> Rf1-e1 <b> b7-b5 <w> e4-e5 <b> Nf6-d7 <w> Nd2-f1 <b> a7-a5 <w> h2-h4 <b> c5-c4 <w> d3-d4 <b> b5-b4 <w> c2-c3 <b> a5-a4 <w> a2-a3 <b> b4xc3 <w> b2xc3 <b> Nc6-a5 <w> h4-h5 <b> Na5-b3 <w> Ra1-a2 <b> Nd7-b8 <w> Bc1-f4 <b> Nb8-a6 <w> h5-h6 <b> g7-g6 <w> Nf1-h2 <b> Na6-c7 <w> Nh2-g4 <b> Nc7-b5 <w> Qd1-c2 <b> Nb5xa3 <w> Ra2xa3 <b> Be7xa3 <w> Ng4-f6+ <b> Kg8-h8 <w> Nf3-g5 <b> Ba3-e7 <w> Nf6xh7 <b> a4-a3 <w> Nh7xf8 <b> Qd8xf8 <w> Qc2-a2 <b> Bc8-d7 <w> Bg2-f3 <b> Ra8-b8 <w> Bf3-d1 <b> Bd7-a4 <w> Kg1-g2 <b> Ba4-c6 <w> Ng5-f3 <b> Nb3-a5 <w> Re1-h1 <b> Rb8-b2 <w> Qa2-a1 <b> Na5-b3 <w> Bd1xb3 <b> c4xb3 <w> Bf4-g5 <b> Rb2-a2 <w> Qa1-b1 <b> Ra2-b2 <w> Qb1-c1 <b> Rb2-c2 <w> Qc1-f4 <b> b3-b2 <w> Bg5-f6+'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tokenizers.Tokenizer' object has no attribute 'eos_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/data/evan/CS285_Final_Project/nanoGPT/data/lichess/test_tokenizers.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://tunnel%2Bjiaolab-cluster/data/evan/CS285_Final_Project/nanoGPT/data/lichess/test_tokenizers.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tokenizer\u001b[39m.\u001b[39;49meos_token\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tokenizers.Tokenizer' object has no attribute 'eos_token'"
     ]
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(example):\n",
    "        #ids = enc.encode_ordinary(example['text']) # encode_ordinary ignores any special tokens\n",
    "        ids = tokenizer.batch_encode(example['game'])\n",
    "        #ids.append(enc.eot_token) # add the end of text token, e.g. 50256 for gpt2 bpe\n",
    "        # note: I think eot should be prepended not appended... hmm. it's called \"eot\" though...\n",
    "        out = {'ids': ids, 'len': len(ids)}\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
